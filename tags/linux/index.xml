<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Axel's Webpage</title><link>https://axelvanherle.xyz/tags/linux/</link><description>Recent content in Linux on Axel's Webpage</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 13 Sep 2023 20:58:41 +0200</lastBuildDate><atom:link href="https://axelvanherle.xyz/tags/linux/index.xml" rel="self" type="application/rss+xml"/><item><title>How i made my room just a little smarter using a rpi and AliExpress</title><link>https://axelvanherle.xyz/blog/2024-03-12_raspiroommonitor/</link><pubDate>Tue, 12 Mar 2024 20:08:30 +0100</pubDate><guid>https://axelvanherle.xyz/blog/2024-03-12_raspiroommonitor/</guid><description>&lt;p>Let me start this off by prefacing that i made my room just a little smarter, nothing too crazy. This post is going to be about how i used a Raspberry Pi, Python, Grafana, Prometheus, Docker and some sensors that i picked up from AliExpress for a few bucks.&lt;/p>
&lt;h2 id="so-what-the-hell-did-i-make">So what the hell did i make?&lt;/h2>
&lt;p>Well, take a look for yourself;&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>OpenweatherAPI &amp;amp; System metrics&lt;/th>
&lt;th>Bedroom &amp;amp; Bathroom&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;img src="https://axelvanherle.xyz/img/2024-03-12_rpimonitor/db1.png" alt="Dashboard 1">&lt;/td>
&lt;td>&lt;img src="https://axelvanherle.xyz/img/2024-03-12_rpimonitor/db2.png" alt="Dashboard 2">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;img src="https://axelvanherle.xyz/img/2024-03-12_rpimonitor/db4.png" alt="Dashboard 4">&lt;/td>
&lt;td>&lt;img src="https://axelvanherle.xyz/img/2024-03-12_rpimonitor/db3.png" alt="Dashboard 3">&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>What you see is a couple of dashboard that allow me to monitor a bunch of metric in and around my room. A dashboard has been created that allows to me track the temperature and humidity in by bed and bathroom. In addition to tracking those two in my bedroom i also track the light intensity, I could&amp;rsquo;ve done that in the bathroom too but who cares about that if we&amp;rsquo;re being honest here.&lt;/p>
&lt;p>In addition to that I also track the system resources of the Pi its running on, and i track a bunch of metrics from outside my room (the feels-like temperature, the temperature, the humidity, the pressure, the wind speed and a bunch of others.)&lt;/p>
&lt;p>If you&amp;rsquo;re interested in setting this up for yourself I have made a howto which you can find on the &lt;a href="https://github.com/axelvanherle/raspi-room-monitor">GitHub page&lt;/a>.&lt;/p>
&lt;h2 id="what-did-i-need">What did i need?&lt;/h2>
&lt;p>Like previously mentioned i used a Raspberry Pi, Python, Grafana, Prometheus, Docker and some sensors from AliExpress.&lt;/p>
&lt;h4 id="raspberry-pi">Raspberry Pi&lt;/h4>
&lt;p>The rpi is going to host everything I&amp;rsquo;m going to be talking about. You might wonder why i opted for this option, and it&amp;rsquo;s quite simple to be honest; i had it laying around. If i didn&amp;rsquo;t have a rpi available to me i probably would&amp;rsquo;ve used something cheaper. I think my project should be portable to anything else, but i don&amp;rsquo;t have access to those to test. Mileage may vary! The rpi is a great low-power option, but not as cost effective these days (sadly).&lt;/p>
&lt;h4 id="python">Python&lt;/h4>
&lt;p>I ended up using this because it&amp;rsquo;s just easy to develop in. Lots of examples to be found online, and modules to read my sensors ready to go. Soydev alert!&lt;/p>
&lt;h4 id="grafana">Grafana&lt;/h4>
&lt;p>I ended up picking Grafana because it&amp;rsquo;s a great at visualizing and processing data. This component is responsible for the actual dashboard. Later I&amp;rsquo;m going to be talking about what components i use to actually gather the data, but firstly I&amp;rsquo;m going to be talking about what I&amp;rsquo;m using to visualize it. It&amp;rsquo;s honestly been a pleasure to work with. It was a breeze to setup and get every service hooked into it. It aims to make creating beautiful dashboards a breeze, and its succeeded in this. After creating my first dashboard and playing around with it a bit i was hooked, it&amp;rsquo;s made visualizing my data a pleasure.&lt;/p>
&lt;h4 id="prometheus">Prometheus&lt;/h4>
&lt;p>This is a bit more technical, but it&amp;rsquo;s an essential component to this project. I leaned towards Prometheus primarily because it&amp;rsquo;s a powerhouse when it comes to monitoring and data collection. This tool offers me a centralized hub for all my monitoring needs. This tool scrapes the data from my various python script and stores these metrics. You can essentially look at it as being the backbone of the monitoring setup. A python script collects the data from a sensor, and Prometheus is responsible for scraping this data, and allowing it to be visualized in Grafana.&lt;/p>
&lt;p>I picked this because its very extensible. It allows me to easily scrape endpoints and store said data. To give an example, i also have a ESP32 in my bathroom responsible for collecting the temperature and humidity. What Prometheus allows me to do is very easily scrape this data from the ESP, and publish it too the rpi. This means that i can have x amount of devices communicating with my dashboards all on their own. Want to add a sensor? Just tell Prometheus to scrape said sensor and that is that. Very extensible, very cool. It&amp;rsquo;s like having a smart assistant who&amp;rsquo;s always keeping an eye on things.&lt;/p>
&lt;h4 id="docker">Docker&lt;/h4>
&lt;p>This one is also a bit more technical, and i didn&amp;rsquo;t necessarily need to use it. I could&amp;rsquo;ve gone the traditional route, installing each component directly onto the Raspberry Pi. But think of Docker as my way of wrapping everything up in a nice, portable package. It really excels at making everything reproducible, allowing you to easily run my stack if you so please. It also allows me to clean up some code, and call a single command to get my entire stack up and running!&lt;/p>
&lt;p>I used two services that docker offers; a compose file and a dockerfile. What the compose file allows me to do is define each service individually. It allows me to pass arguments, define rules, and the likes. The dockerfile is used so i can transform all my python scripts into a neat little service i can call from the compose file. It also allows me to define dependencies, and the likes.&lt;/p>
&lt;h4 id="sensors">Sensors&lt;/h4>
&lt;p>I ended up using a DHT11, DHT22 and a BH1750. I honestly wouldn&amp;rsquo;t have used the DHT11, but i had it laying around. If i had the option i would&amp;rsquo;ve used the DHT22 twice.&lt;/p>
&lt;p>The DHT11 and DHT22 allow me to monitor the temperature and humidity in my bathroom, and bedroom respectively. The DHT22 is just a better, more accurate version of the DHT11.&lt;/p>
&lt;p>The BH1750 is a lux monitor. It allows me the measure the light intensity.&lt;/p>
&lt;p>I might pick up a CO2 monitor, but these are a bit more expensive and i didn&amp;rsquo;t really feel the need to.&lt;/p>
&lt;h2 id="lets-get-a-bit-more-technical">Let&amp;rsquo;s get a bit more technical.&lt;/h2>
&lt;p>In this section I&amp;rsquo;m delving a bit deeper into how i got each building block up and running. If you don&amp;rsquo;t care, you&amp;rsquo;d just skip ahead to the next section (i promise you wouldn&amp;rsquo;t hurt my feelings).&lt;/p>
&lt;p>Let&amp;rsquo;s start with the python scripts, which you can find &lt;a href="https://github.com/axelvanherle/raspi-room-monitor/tree/main/src">here&lt;/a>. I&amp;rsquo;ll get into the *_metrics.py first. These are the script responsible for collecting the metrics from all the different endpoints. They create a Prometheus gauge, allow me to read the data, and push them to a gauge. In the main.py i setup a Prometheus server, read the data from the various metrics and publish them.&lt;/p>
&lt;p>I collect data from all the previous sensor but i also got a little fancy with it. In addition to collecting metrics from the different sensor i also do API calls to the openweatherAPI. However you need a API key, and some additional location information for this to be effective. That&amp;rsquo;s where the config.py comes is. Because i define these scripts as a docker compose server i can pass the variables from the .env file to this. In other words, you get a API key, your LAT and LON and put these into the .env file. Docker compose passes these through to the container, and config.py retrieves these and allows me to correctly pass said variables to my script that collects the metrics from the openweatherAPI. It effectively allows me to not dox myself online, and allow you to not have to modify code. Very cool!&lt;/p>
&lt;p>In the main.py i setup logging, the Prometheus server, and its where i systematically query easy metric collection script. I query each script, then publish the results to a Prometheus server.&lt;/p>
&lt;p>Whilst we&amp;rsquo;re on Prometheus, it&amp;rsquo;s what I&amp;rsquo;m going to delve into next. This is setup as a separate service from what I&amp;rsquo;ve previously talking about. We have a bunch of Prometheus servers running, some on the rpi as a python script and another on the ESP in my bathroom. What the Prometheus service allows me to do is query each of these separate running server and save their data. All i needed to do was create a &lt;a href="https://github.com/axelvanherle/raspi-room-monitor/blob/main/prometheus_config.yml">configuration file&lt;/a> where i tell the service what to query. In my case it has to query the python scripts, and the ESP32 in my bathroom.&lt;/p>
&lt;p>Okay, now we can query and store the data from all of my sensors and my devices but how do we process and visualize it? That&amp;rsquo;s where Grafana comes in it. Defined as another service in my docker compose I&amp;rsquo;ve also kept provisioning in mind, allowing me to connect to the Prometheus backbone and make my dashboards stateless. Effectively what this means is that the dashboards and data sources aren&amp;rsquo;t only saved in one container, meaning that when it gets wiped, i don&amp;rsquo;t need to set those up again.&lt;/p>
&lt;p>Whilst talking about docker ill talk about what I&amp;rsquo;ve setup. We have a docker compose file where i define each service, pass the correct variables and or files and give it the correct port mappings. This allows me and you to simply run the compose file and get each service up and running. I use a dockerfile to containerize my python scripts. I played around with GitHub Actions to automate and crosscompile for the rpi but this ended up not being worth it. No time was to be saved by downloading a pre-build container and I&amp;rsquo;d have to solve a whole bunch of dependencies issues because I&amp;rsquo;m compiling them on a different architecture. I didn&amp;rsquo;t feel like solving these issues to maybe save a few seconds and run into issues on devices i can&amp;rsquo;t test with. You&amp;rsquo;re gonna have to build it yourself, ya filthy animal!&lt;/p>
&lt;p>In other words, everything that I&amp;rsquo;ve setup is pretty user-friendly. All the user is expected to do is configure their jobs in the prometheus_config, and run the compose file.&lt;/p>
&lt;h2 id="in-conclusion">In conclusion&lt;/h2>
&lt;p>It&amp;rsquo;s been a fun project to work on that&amp;rsquo;s brought me some insight into my room and what&amp;rsquo;s going on around it. It&amp;rsquo;s not something that i really needed, but it sure is a nice addition for a few bucks spent. On a quick calculation i spent around 7 bucks on it. Most of that budget went to the ESP32, which cost me ~4 euros. I was lucky to have a bunch of stuff already laying about like the Raspberry Pi, a breadboard, the DHT11 sensor, jumper wires,&amp;hellip; The only things i needed to get were the DHT22, BH1750 and the ESP32. I could&amp;rsquo;ve built this project using only what i already had laying around (which i did and you can find &lt;a href="https://github.com/axelvanherle/raspi-dht11-monitor">here&lt;/a>) however this solution felt a bit too simple for me, so i expanded into what became this project.&lt;/p></description></item><item><title>Why you should setup a DNS sinkhole</title><link>https://axelvanherle.xyz/blog/2023-11-27_dnssinkhole/</link><pubDate>Mon, 27 Nov 2023 13:37:38 +0100</pubDate><guid>https://axelvanherle.xyz/blog/2023-11-27_dnssinkhole/</guid><description>&lt;p>I&amp;rsquo;ve know about the concept for years now, but i always imagined it to be a pain to setup. In said imagination it was going to take me days to set this up, and i recently got to it because my exams were over.&lt;/p>
&lt;p>Only thing is; it took me a grand total of 30 minutes to set it up. This blogpost is going to be about how and what i did to set it up, and hopefully inspire you to do the same.&lt;/p>
&lt;h1 id="the-what">The what&lt;/h1>
&lt;p>Now what the fuck is a DNS sinkhole? Simply put it&amp;rsquo;s a network management tool blocks unwanted traffic. Less simply put a DNS sinkhole acts as a DNS server which intercepts DNS queries. When it receives a query for a domain that is on a blocklist (a list of domains that it should redirect to jack squat) it will prevent said device to connect to said domain.&lt;/p>
&lt;p>Imagine this scenario; I do not wish for TikTok to be reachable on my network, how would a DNS sinkhole help me?&lt;/p>
&lt;ol>
&lt;li>A device makes a DNS query to resolve the domain. (In this case it would attempt to resolve &lt;a href="https://www.tiktok.com">www.tiktok.com&lt;/a> into an IP).&lt;/li>
&lt;li>Instead of going to a regular DNS server and getting the domain resolved it would query the DNS sinkhole.&lt;/li>
&lt;li>Said DNS sinkhole checks to see if the domain is on its blocklist, and if it is it would respond with a null route effectively blocking access.&lt;/li>
&lt;/ol>
&lt;p>I have taken the liberty to block TikTok on my network and this is what happens;
&lt;img src="https://axelvanherle.xyz/img/2023-11-27_sinkhole/tiktok1.webp" alt="TikTok Blocked">
&lt;img src="https://axelvanherle.xyz/img/2023-11-27_sinkhole/tiktok2.webp" alt="TikTok Blocked">&lt;/p>
&lt;p>What you see here is a DNS query getting &amp;ldquo;null routed&amp;rdquo; to 0.0.0.0. In other words, my system queries my DNS sinkhole in attempt to resolve the TikTok domain. Instead of getting a valid IP back that it can connect to it gets a IP that does nothing.&lt;/p>
&lt;h1 id="but-why">But why?&lt;/h1>
&lt;p>Okay, so now that you know &lt;em>what&lt;/em> it is, why would you want it?&lt;/p>
&lt;p>Here is the kicker; it&amp;rsquo;s capable of blocking way more than TikTok. To give you an idea, since setting this up in my dorm it has blocked ~20% of all my traffic.&lt;/p>
&lt;h2 id="but-what-am-i-blocking">But what am i blocking?&lt;/h2>
&lt;p>To keep things short this allows me to block ads, trackers, annoyances and more over my home network. You can effectively think of it as installing an adblock on your home network. This makes it so my projector, mobile phone, and whatever else i decide to connect to my network reaps these benefits.&lt;/p>
&lt;p>It&amp;rsquo;s not a perfect solution though, since services like YouTube are a bit complexer to block. This however is because of how YouTube ads work, because they are served from the same domain as the actual video content. It however has been capable of blocking ads in certain applications on my projector /shrug.&lt;/p>
&lt;h2 id="how-do-i-choose-what-to-block">How do i choose what to block?&lt;/h2>
&lt;p>Here is where blocklist come in. They are lists of domains that your sinkhole should resolve to a invalid IP. You choose the blocklists to add, based on what they do, what they contain etc.&lt;/p>
&lt;h1 id="the-how">The how&lt;/h1>
&lt;p>So how&amp;rsquo;d i do it? Like previously stated, it took me a grand total of 30 minutes.&lt;/p>
&lt;p>All i needed was a raspberry pi to do it, but you can run it on whatever you please.&lt;/p>
&lt;p>I don&amp;rsquo;t plan on going in depth here since the documentation of whatever service you choose is going to provide this better than i could, but it was a very straightforward procedure.&lt;/p>
&lt;p>I simply flashed my pi with the latest lite image, looked up the documentation for setting up AdGuard Home on it (which was a glorified one liner i could copy-paste), added a few blocklists and set my router to use the pi as the primary DNS server.&lt;/p>
&lt;p>It really is that simple, anyone could do it. Which is why i encourage you, yes you to take a look at AdGuard Home, or Pi-hole and set it up for yourself. It barely takes any time to setup, and provides you with a experience that is definitely worth the effort. It enhances your security, privacy and overall experience on the web. Take more control of your home network and set it up today!&lt;/p></description></item><item><title>My ~25 KiB site is simply better; ranting about the current state of the web, soydevs beware.</title><link>https://axelvanherle.xyz/blog/2023-10-25_kibsite/</link><pubDate>Sat, 07 Oct 2023 00:04:23 +0200</pubDate><guid>https://axelvanherle.xyz/blog/2023-10-25_kibsite/</guid><description>&lt;p>Let me start this post off by prefacing that i&amp;rsquo;m not counting images here. I&amp;rsquo;m talking about pure HTML/CSS/JS or whatever bullshit frameworks a site might use.&lt;/p>
&lt;p>In today&amp;rsquo;s world most websites are simply bloated, no way around it. But what exactly am I talking about here? These days, most sites are 5-10-20MiB. But why is this? It would be simple to blame it onto soydevs, but often multiple megabyte&amp;rsquo;s of difference are ads, trackers and junk being loaded in.&lt;/p>
&lt;p>Right off the bat, you might be wondering; &amp;ldquo;What the hell does 25 KiB even mean?&amp;rdquo; Well, think of it like this: it&amp;rsquo;s roughly the size of a small text file on your computer, the kind that takes up almost no space. Hell, a simple photo you snap with your phone is many times larger than that. So, when I say my website is 25 KiB, it&amp;rsquo;s like I&amp;rsquo;ve squeezed all the info into that tiny text file, without any of the bloat and unnecessary garbage. Pretty neat, right?&lt;/p>
&lt;h1 id="i-thought-size-doesnt-matter">I thought size doesn&amp;rsquo;t matter?&lt;/h1>
&lt;p>In other cases, it might be more dependent on how you use what you have, rather than what you have but that certainly isn&amp;rsquo;t the case here. Less is more when it comes to websites, especially when it&amp;rsquo;s all loaded up with bullshit that have no use to you.&lt;/p>
&lt;p>Having a big website loaded with frameworks and fancy effects might be impressive, but it&amp;rsquo;s a &lt;em>huge&lt;/em> pain in the ass when I want to load it on a device with a slow network speed and or a slow device. And don&amp;rsquo;t get me wrong, a man can certainly appreciate a well designed website with bells and whistles, but more often than not these are bells and whistles that make the site annoying, difficult and slugish to navigate. What&amp;rsquo;s wrong with putting whatever content you have on a simple site, like the one you&amp;rsquo;re currently looking at. I can bet you&amp;rsquo;re not missing the slow loading times, pop-ups, or unnecessary animations, and whatever else that often plague the modern web. A streamlined, efficient site respects your time, delivering the essence of the content without any added bullshit. Shoving all that crap onto a website is like trying to drink from a fire hose. You want to read the content, not get blasted by unnecessary animations and side shows, or whatever else they decide you want.&lt;/p>
&lt;p>Most website&amp;rsquo;s are simply so cluttered with added &amp;ldquo;features&amp;rdquo; that are ruining your experience. I can&amp;rsquo;t tell you how often I&amp;rsquo;ve faced popups, info being crammed in small areas, and I&amp;rsquo;m sure you can imagine plenty more. There is nothing wrong with a minimal site like this; I would way rather consume what I&amp;rsquo;m interested in on sites like &lt;a href="https://motherfuckingwebsite.com/">https://motherfuckingwebsite.com/&lt;/a> or &lt;a href="https://news.ycombinator.com/news">https://news.ycombinator.com/news&lt;/a>. It&amp;rsquo;s simple, I can get what I&amp;rsquo;m looking for without being served 10MiB of bullshit I simply do not care about. My &lt;em>entire&lt;/em> site takes ~25 KiB (might be more when you&amp;rsquo;re reading this), you simply cannot convince me that you need a 5MiB+ site just to serve me what I&amp;rsquo;m looking for.&lt;/p>
&lt;p>To put this into perspective; my 25 KiB website is 0.25% the size of a 10MiB webpage. Another way of looking at it is that my &lt;em>entire website&lt;/em> is about 400 times smaller than a 10MiB &lt;em>page&lt;/em>. And this is just comparing my &lt;em>entire site&lt;/em> to a 10MiB page. Hopefully that puts into perspective how ridiculously bloated some sites are, and how crammed they are with &amp;ldquo;features&amp;rdquo; that you simply do not care about. Are you missing something from my site? If i were to bet you&amp;rsquo;re not; you wanted to read this post and are &lt;em>just&lt;/em> doing so. I&amp;rsquo;m not serving you trackers, ads, unnecessary JS, and you&amp;rsquo;re not missing them! Who would&amp;rsquo;ve thought eh?&lt;/p>
&lt;p>Now if i were to compare pages this is a way bigger difference, and its more logical to compare page size rather than the whole site. The average size of a page on my site is about 5KiB, all in. This would mean my page is about 0.05% the size compared to a 10MiB one. That means my page is 2000 times smaller! This is a shit ton.&lt;/p>
&lt;p>You probably know one of those slugish sites i&amp;rsquo;m talking about, but if you don&amp;rsquo;t you could simply google any recipe and get the gist of what I&amp;rsquo;m talking about on the first few websites. Can you imagine how much nicer your experience would be if the all websites were snappy and quick loading without pushing info you don&amp;rsquo;t care about? If you are given the decision between a bloated slugish site, or a nice and snappy minimalist site you are more than likely choosing the minimalist option, and the bigger sites you use often are just that; minimalist. A few examples of this are google, wikipedia, ebay, and you can probably think of a few more. It bugs me that the modern web does not respect the user, and opts to push ads trackers and whatever else bullshit they call features in your face. There is nothing wrong with a simple website, and it&amp;rsquo;s not even an issue for nerds to complain about, but it&amp;rsquo;s a true issue on the modern web, especially for people with slower devices and network speeds. 20MiB Is a shit ton for some people when it&amp;rsquo;s all fairy dust.&lt;/p>
&lt;p>I&amp;rsquo;m also sure you&amp;rsquo;ve had the displeasure of using one of these sites on your mobile device and have been unable to navigate it. This is an issue that has been happing and bugging me for a while now. You&amp;rsquo;re telling me you learnt your craft for years and aren&amp;rsquo;t capable of serving your site on a mobile device? It just proves that under the surface of it all they don&amp;rsquo;t care about your experience. They want to impress you, and shove as much ads and trackers down your throat. This behavior doesn&amp;rsquo;t stop at websites, but that&amp;rsquo;s another rant for another day.&lt;/p>
&lt;p>To put it shortly; it&amp;rsquo;s simply a much nicer experience navigating and reading a minimalist site like this, compared to something that has all these unnecessary additions made to it. It&amp;rsquo;s snappy, works and respects your time. It doesn&amp;rsquo;t attempt to please you; it just pleases you and doesn&amp;rsquo;t treat you like a toddler.&lt;/p>
&lt;h1 id="so-how-did-i-do-it">So how did i do it?&lt;/h1>
&lt;p>Here&amp;rsquo;s the kicker; it wasn&amp;rsquo;t hard at all. In fact, it would be more difficult for me to serve you a bloated site. I&amp;rsquo;ve used the &lt;code>hugo&lt;/code> site generator with the &lt;a href="https://github.com/LukeSmithxyz/lugo">lugo&lt;/a> theme. All i had to do was make a simple &lt;code>index.html&lt;/code> file with some hugo variables and give it a stylesheet i enjoy. I didn&amp;rsquo;t even pay mind to what i was doing; i simply did what i wanted and ended up with a average page-size around 5KiB. Let me once again attempt to put this into perspective; imagine i added bells and whistles that would make the size of the average page 100 times bigger. Yes, 100 times! Now that&amp;rsquo;s a shit ton right? What could i possible add to make it 100 times bigger? I simply wouldn&amp;rsquo;t even know. But if I were to do this, my site would only be ~1/10th of a single MiB. And most pages are still 5, 10, 20 times bigger than even that! It&amp;rsquo;s absolutely bonkers.&lt;/p></description></item><item><title>How i organized my dotfiles</title><link>https://axelvanherle.xyz/blog/2023-09-13_dotfiles/</link><pubDate>Wed, 13 Sep 2023 20:58:41 +0200</pubDate><guid>https://axelvanherle.xyz/blog/2023-09-13_dotfiles/</guid><description>&lt;h1 id="how-i-organized-my-dotfiles-using-git">How i organized my dotfiles using git.&lt;/h1>
&lt;p>It seems appropriate to start this post off with giving an explanation as to &lt;em>why&lt;/em> i would want to do this.&lt;/p>
&lt;p>Luckily this is simple to explain; I&amp;rsquo;m a lazy fucker, that&amp;rsquo;s why. No really, that&amp;rsquo;s pretty much all there is too it. I simply wanted to make the process of syncing my dotfiles to and from multiple of my systems (most notably my laptop and my desktop) easier.&lt;/p>
&lt;p>I used to do this manually, where i had set up a repo where i would manually &lt;code>cp&lt;/code> and then &lt;code>mv&lt;/code> my config files into them, but this took minutes. Like i said, I&amp;rsquo;m lazy and had time on my hands.&lt;/p>
&lt;h2 id="how-i-did-it">How i did it&lt;/h2>
&lt;p>I took some inspiration from &lt;a href="https://www.atlassian.com/git/tutorials/dotfiles">atlassian&amp;rsquo;s&lt;/a> blogpost. They also took some inspiration so it&amp;rsquo;s a &lt;a href="https://youtu.be/Lr-KHezBqX0?t=242">https://youtu.be/Lr-KHezBqX0?t=242&lt;/a> typa situation we got on our hands.&lt;/p>
&lt;p>With that disclosure out of the way; here&amp;rsquo;s how i did it.&lt;/p>
&lt;p>To get things started i set up a bare git repo in my home dir named &lt;code>.cfg&lt;/code> (cfg is short for config). I had actually never even heard of a bare repo, but after learning about it, it really seemed the play to sync and manage my dotfiles. To keep things short, the advantage of a bare repo is that I&amp;rsquo;m tracking the actual config files themselves, instead of symlinking or manually copying my config files to a working directory.&lt;/p>
&lt;p>I did this by doing a simple &lt;code>git init --bare $HOME/.cfg&lt;/code>. All this does is create a bare git repo inside &lt;code>$HOME&lt;/code>, or in other words home sweet home.&lt;/p>
&lt;p>After that i set up the alias &lt;code>config='/usr/bin/git --git-dir=$HOME/.cfg/ --work-tree=$HOME'&lt;/code>. We do this so we have a simple command we can use where-ever we are in our system to interact with our config files. This works by executing git and specifying that we are using the &lt;code>$HOME/.cfg&lt;/code> repo. We also set the working tree, aka the directory which our git repo is supposed to be tracking. Since we are managing our dotfiles, we are tracking &lt;code>$HOME&lt;/code>. If you are a more organized user than i am, you could do all of this inside &lt;code>~/.config&lt;/code>.&lt;/p>
&lt;p>I simply put this alias inside my &lt;code>.zshrc&lt;/code>, since that&amp;rsquo;s my preferred shell.&lt;/p>
&lt;p>Then we tell our git repo to not show us any untracked files by setting &lt;code>config config --local status.showUntrackedFiles no&lt;/code> this flag. All this does is make sure we aren&amp;rsquo;t bombarded with a huge list of untracked files when doing &lt;code>config status&lt;/code>.&lt;/p>
&lt;p>That was all when it comes to setting up our local repo. We&amp;rsquo;ve now successfully set up a git repo to &lt;em>locally&lt;/em> sync our files. But you might ask, how do i access this repo from a different machine? And to be honest, that&amp;rsquo;s a great question. I used github for this, but you can use whatever you want.&lt;/p>
&lt;p>If you do decide to use github you need to add the remote repository to you local configuration (something you need to do for any remote repo). I simply ran &lt;code>config remote add origin git@github.com:&amp;lt;your username&amp;gt;/&amp;lt;name of your gh repo&amp;gt;.git&lt;/code>&lt;/p>
&lt;p>Keep in mind that you do need valid SSH keys for this to work, i had to generate a pair and add them to my github account.&lt;/p>
&lt;p>After this you are able to push and pull to your remote github repo using all your regular git commands, but instead of git we are using the &lt;code>config&lt;/code> alias that we just setup. Imagine running commands like &lt;code>config commit -am &amp;quot;rewrite nvim config&amp;quot;&lt;/code>, &lt;code>config status&lt;/code>, &lt;code>config push&lt;/code>,&amp;hellip;&lt;/p>
&lt;p>We currently have this git repo setup on one machine, but there are a few steps to get it setup on another machine.&lt;/p>
&lt;p>First things first is setting up a safety net on our local machine before pushing it to remote. We don&amp;rsquo;t want to be encountering any weird recursion scenarios, and to make sure this does not happen is by adding &lt;code>.cfg&lt;/code> to our &lt;code>.gitignore&lt;/code>. One can do this by running &lt;code>echo &amp;quot;.cfg&amp;quot; &amp;gt;&amp;gt; .gitignore&lt;/code>. Then we add this file to our git repo by running &lt;code>config add .gitignore&lt;/code>. Make sure to also push this to the remote repo by committing it and pushing doing &lt;code>config commit -am &amp;quot;add .cfg to .gitignore&amp;quot;&lt;/code> and &lt;code>config push&lt;/code>.&lt;/p>
&lt;p>After setting up our safety net, we are safeguarded from any recursion issues and we are ready to clone to another machine.&lt;/p>
&lt;p>To clone our repo simply run &lt;code>git clone --bare &amp;lt;git-repo-url&amp;gt; $HOME/.cfg&lt;/code>. This command clones the repo to &lt;code>.cfg&lt;/code> located in your home directory. After cloning we set up a alias in our current shell scope by running &lt;code>alias config='/usr/bin/git --git-dir=$HOME/.cfg/ --work-tree=$HOME'&lt;/code>. We do this in this scope because your freshly pushed dotfiles should contain this alias, so if you haven&amp;rsquo;t added it already now is the time.&lt;/p>
&lt;p>When we have the repo cloned we are ready to checkout our freshly cloned repo. In simple terms, this deploys our dotfiles on our system. To do this, run &lt;code>config checkout&lt;/code>. You might get an error about overwriting files. To &amp;ldquo;fix&amp;rdquo; this error we are going to be moving the files that are giving us trouble into a different folder named &lt;code>.config-backup&lt;/code>. We do this in the off-chance anything goes wrong.&lt;/p>
&lt;p>Run&lt;/p>
&lt;pre tabindex="0">&lt;code>sudo mkdir -p .config-backup &amp;amp;&amp;amp; \
config checkout 2&amp;gt;&amp;amp;1 | grep -E &amp;#34;\s+\.&amp;#34; | awk {&amp;#39;print $1&amp;#39;} | \
while read -r file; do
dir=$(dirname &amp;#34;.config-backup/${file}&amp;#34;)
mkdir -p &amp;#34;${dir}&amp;#34;
mv &amp;#34;${file}&amp;#34; &amp;#34;.config-backup/${file}&amp;#34;
done &amp;amp;&amp;amp; config config --local status.showUntrackedFiles no
&lt;/code>&lt;/pre>&lt;p>This is mostly freeloading off the original guides script, but i had an issue where it didn&amp;rsquo;t create parent directories so i added the while loop with a little bit of help from my buddy ChatGPT. I also added the &lt;code>config config --local status.showUntrackedFiles no&lt;/code> line at the end, so we don&amp;rsquo;t have to run that separately. Like i said, I&amp;rsquo;m lazy.&lt;/p>
&lt;p>Once that has run without any errors you&amp;rsquo;re done, you can now clone and sync your dotfiles on as many systems as you want.&lt;/p></description></item><item><title>About</title><link>https://axelvanherle.xyz/about/</link><pubDate>Tue, 22 Aug 2023 16:23:19 +0200</pubDate><guid>https://axelvanherle.xyz/about/</guid><description>&lt;p>Hi there. If you clicked on this page, you probably want to know more about me. So, here goes. I&amp;rsquo;m currently a student and plan on being one for a bit longer. I don&amp;rsquo;t have an interest in working full-time as of now, as I still enjoy studying. I plan on pursuing a master&amp;rsquo;s degree, and perhaps a doctorate if I feel inclined. But who knows? A lot can change.&lt;/p>
&lt;p>I&amp;rsquo;ve been interested in technology for as long as I can remember. From gaming with my dad to tinkering with my grandmother&amp;rsquo;s computer system. Once I enrolled in my current field of study, Electronics ICT, this passion truly ignited. I&amp;rsquo;m particularly drawn to the ICT aspect of things. I&amp;rsquo;m especially interested in Linux and FOSS software. Over time, I&amp;rsquo;ve developed a more conservative view on software, preferring simple, lightweight applications over their complex counterparts.&lt;/p>
&lt;p>This site is one of the projects I took on on as my passion grew. I believe everyone should have a personal site they can call their own. I created this site as a way to share my passion for the things I care about and the projects I undertake.&lt;/p>
&lt;p>If you&amp;rsquo;d like to contact me, details are available on my &lt;a href="https://axelvanherle.xyz/contact/">contact&lt;/a> page. And if you&amp;rsquo;re curious about the software I use daily, feel free to check out the &lt;a href="https://axelvanherle.xyz/programs/">programs&lt;/a> page.&lt;/p></description></item><item><title>Contact Me</title><link>https://axelvanherle.xyz/contact/</link><pubDate>Tue, 22 Aug 2023 16:23:19 +0200</pubDate><guid>https://axelvanherle.xyz/contact/</guid><description>&lt;ul>
&lt;li>&lt;a href="mailto:axelvanherle@outlook.com">axelvanherle@outlook.com&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>If you are intrested, you can also find some of my work on &lt;a href="https://github.com/axelvanherle">github&lt;/a>.&lt;/p></description></item><item><title>How i beat Netflix's location lock.</title><link>https://axelvanherle.xyz/blog/2023-08-19_arrkotje/</link><pubDate>Sat, 19 Aug 2023 00:00:00 +0000</pubDate><guid>https://axelvanherle.xyz/blog/2023-08-19_arrkotje/</guid><description>&lt;h1 id="how-i-beat-netflixs-location-lock">How i beat Netflix&amp;rsquo;s location lock.&lt;/h1>
&lt;p>Netflix recently introduced a new feature to their service, that being &amp;ldquo;Netflix-Households&amp;rdquo;. And to put it bluntly, it has fucked me. I can no longer watch Netflix in my dorm room, without paying whatever Netflix prices it as. I no longer felt like using Netflix at all because of this, so i decided that i was going to selfhost whatever the equivalent of it is.&lt;/p>
&lt;p>A quick note, i go over most of the software used briefly. If you want to know more, i encourage you to research it.&lt;/p>
&lt;h2 id="first-things-first">First things first&lt;/h2>
&lt;p>To get my homelab started i was going to need something to run it on. Luckily i had an old Dell optiplex laying around, and for my purposes it&amp;rsquo;s more than enough. I&amp;rsquo;ve been using Arch for sometime now, and in this period it has become my favorite distro by far. Following this trend, i installed it. After installing it i wanted to be able to get a shell without plugging a monitor and keyboard in if i want to interact with it. For this i used &lt;a href="https://cockpit-project.org/">cockpit&lt;/a>, it&amp;rsquo;s a web-based interface to interact with the optiplex, from now on referred to as the server.&lt;/p>
&lt;h2 id="okay-what-now">Okay, what now?&lt;/h2>
&lt;p>Next up was figuring out what i wanted. Of course I&amp;rsquo;m not one to break rules. So everything described in this blog-post is legal, i wouldn&amp;rsquo;t tell you how to download &lt;a href="https://www.youtube.com/watch?v=hrE4Xc63uNQ">copyrighted&lt;/a> content. Everything i plan on using this server for is purely legal, I&amp;rsquo;m most definitely not breaking any rules here.&lt;/p>
&lt;p>With that out of the way, let&amp;rsquo;s talk about what i wanted. I wanted something that was easy, I did not want to lose any QOL features that Netflix offered. Knowing what i wanted, i found these programs that do it for me.&lt;/p>
&lt;h3 id="programs">Programs&lt;/h3>
&lt;p>Listing the program will be done in order of what the user interacts with going down the list.
If this isn&amp;rsquo;t clear, it will be soon enough.&lt;/p>
&lt;p>The user is expected to primarily interact with one service; &lt;code>plex&lt;/code>.
You can think of Plex as the Netflix part of the whole operation. It&amp;rsquo;s responsible for interacting with the media files (movies and shows). In other words, it&amp;rsquo;s how you actually watch the media.&lt;/p>
&lt;p>Because of how my setup works, you have to download the movies before you are actually able to watch them. This part took the longest to setup, so it&amp;rsquo;ll take the longest to explain.&lt;/p>
&lt;p>To request media, the user is expected to interact with &lt;code>overseerr&lt;/code>. This is a request and media discovery tool built to work with Plex. In other words, its a service that allows me to discover media to download. Think of it like you&amp;rsquo;re browsing around netflix.&lt;/p>
&lt;p>Great. Now we can request media, but we still need to be able to download it. That&amp;rsquo;s where &lt;code>radarr&lt;/code>, &lt;code>sonarr&lt;/code>, &lt;code>prowlarr&lt;/code> and &lt;code>qbittorrent&lt;/code> come in.&lt;/p>
&lt;p>Okay, so let&amp;rsquo;s say I wanted to download the movie &amp;ldquo;Foo&amp;rdquo;. I would go to overseerr, search it and request it. If it&amp;rsquo;s a movie it goes to radarr, and if it&amp;rsquo;s a show it goes to sonarr. So, now radarr or sonarr know i want to download &amp;ldquo;Foo&amp;rdquo;. However, where does it search for this? Well, that&amp;rsquo;s where prowlarr comes in. Prowlarr is an index manager, what this means is that it indexes my favorite torrents sites, to allow sonarr or radarr to search for whatever media i requested.&lt;/p>
&lt;p>So, to recap; the user requested Foo. That got sent to radarr if it&amp;rsquo;s a movie, and sonarr if it were a show. Radarr or sonarr search my favorite torrent sites using prowlarr based on the requirements i set. For example, i set it to look for 4K Remux media first, then 4K Bluray, and it goes down the list, you get the picture.&lt;/p>
&lt;p>Once it found suitable media that matches my requirements, it gets sent to qbittorrent. This tool is responsible for downloading the media.
Now, sonarr or radarr watch the progress, and when it&amp;rsquo;s done downloading they move it to another directory and rename it to a less cluttered name.&lt;/p>
&lt;p>That&amp;rsquo;s pretty much it. I messed around with systemd (for my vpn), and docker to get some of these services up and running. Other than that, i also used the AUR and some official packages. This is the gist of how i set it up, there were some other nuisance involved, but i didn&amp;rsquo;t mention them here.&lt;/p></description></item><item><title>Programs i use</title><link>https://axelvanherle.xyz/programs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://axelvanherle.xyz/programs/</guid><description>&lt;p>You can probably find what i list here on my GitHub in my &lt;a href="https://github.com/axelvanherle/dotfiles">dotfiles&lt;/a> repo.&lt;/p>
&lt;h1 id="basic">Basic&lt;/h1>
&lt;h3 id="operating-system">Operating system&lt;/h3>
&lt;ul>
&lt;li>My favorite disto is Arch, this is also what i run on my server. On my laptop and desktop i run EndeavourOS simply because it&amp;rsquo;s easier to install, and comes with certain things set up OOB, like an AUR helper.&lt;/li>
&lt;/ul>
&lt;h3 id="terminal">Terminal&lt;/h3>
&lt;ul>
&lt;li>I currently use Alacritty, it&amp;rsquo;s minimal enough OOB for me, and offers a way to easily customize it to my liking.&lt;/li>
&lt;/ul>
&lt;h3 id="shell">Shell&lt;/h3>
&lt;ul>
&lt;li>I use zsh as my shell. It&amp;rsquo;s posix compliant, and allows to me add plugins and shit like that. I used Luke Smith&amp;rsquo;s &lt;a href="https://gist.github.com/LukeSmithxyz/e62f26e55ea8b0ed41a65912fbebbe52">config&lt;/a>, with a few added features of my own. It uses vim binds, which is something unmissable in my shell once i started using it.&lt;/li>
&lt;/ul>
&lt;h3 id="wmde">WM/DE&lt;/h3>
&lt;ul>
&lt;li>I currently use Xfce on my desktop, and Gnome on my laptop. I enjoy the simplicity of Xfce on my desktop, and the &amp;ldquo;bloated&amp;rdquo; things Gnome comes with are useful for a machine that needs to justwork on my day to day. I&amp;rsquo;m a heavy touchpad user, and Gnome allows me to customize these to my needs.&lt;/li>
&lt;/ul>
&lt;h3 id="text-editor">Text editor&lt;/h3>
&lt;ul>
&lt;li>Neovim&lt;/li>
&lt;/ul>
&lt;h3 id="browser">Browser&lt;/h3>
&lt;ul>
&lt;li>Firefox, of course.&lt;/li>
&lt;/ul>
&lt;h1 id="utilities">Utilities&lt;/h1>
&lt;h3 id="file-manager">File manager&lt;/h3>
&lt;ul>
&lt;li>I just use whatever my DE comes with. I don&amp;rsquo;t interact with it much, as i primarily use lf. This is built into my shell, so makes it useful to navigate my system in my terminal.&lt;/li>
&lt;/ul>
&lt;h3 id="rss-reader">RSS reader&lt;/h3>
&lt;ul>
&lt;li>Newsboat, set up with vim binds and with organized places where each topic goes.&lt;/li>
&lt;/ul>
&lt;h3 id="image-editor">Image editor&lt;/h3>
&lt;ul>
&lt;li>GIMP&lt;/li>
&lt;/ul></description></item></channel></rss>